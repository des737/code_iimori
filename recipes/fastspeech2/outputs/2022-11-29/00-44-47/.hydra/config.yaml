model:
  netG:
    _target_: vc_tts_template.fastspeech2wGMM.FastSpeech2wGMM
    max_seq_len: 4000
    num_vocab: 53
    encoder_hidden_dim: 256
    encoder_num_layer: 4
    encoder_num_head: 2
    conv_filter_size: 1024
    conv_kernel_size_1: 9
    conv_kernel_size_2: 1
    encoder_dropout: 0.2
    prosody_emb_dim: 64
    extra_conv_kernel_size: 3
    extra_conv_n_layers: 2
    extra_gru_n_layers: 2
    extra_global_gru_n_layers: 2
    gru_hidden_dim: 512
    gru_n_layers: 2
    pp_conv_out_channels: 256
    pp_conv_kernel_size: 3
    pp_conv_n_layers: 2
    pp_conv_dropout: 0.2
    pp_zoneout: 0.1
    num_gaussians: 11
    softmax_temperature: 1.0
    global_gru_n_layers: 2
    global_d_gru: 512
    global_num_gaussians: 10
    global_softmax_temperature: 1.0
    variance_predictor_filter_size: 256
    variance_predictor_kernel_size: 3
    variance_predictor_dropout: 0.5
    pitch_feature_level: 1
    energy_feature_level: 1
    pitch_quantization: linear
    energy_quantization: linear
    pitch_embed_kernel_size: 9
    pitch_embed_dropout: 0.5
    energy_embed_kernel_size: 9
    energy_embed_dropout: 0.5
    n_bins: 256
    decoder_hidden_dim: 256
    decoder_num_layer: 6
    decoder_num_head: 2
    decoder_dropout: 0.2
    n_mel_channel: 80
    encoder_fix: false
    prosody_spk_independence: true
    local_prosody: true
    global_prosody: false
    stats:
      pitch_min: -0.7024055490777836
      pitch_max: 0.5050794978252391
      energy_min: -0.8127368539571762
      energy_max: 0.5676259696483612
    speakers:
      JSUT: 0
      NICT: 1
      Teacher: 2
      FStudent: 3
      MStudent: 4
    emotions: null
    accent_info: 0
verbose: 100
seed: 773
tqdm: tqdm
cudnn:
  benchmark: false
  deterministic: false
data_parallel: false
data:
  train:
    utt_list: data/train.list
    in_dir: dump/LINE_3_sr22050/norm/train/in_fastspeech2/
    out_dir: dump/LINE_3_sr22050/norm/train/out_fastspeech2/
  dev:
    utt_list: data/dev.list
    in_dir: dump/LINE_3_sr22050/norm/dev/in_fastspeech2/
    out_dir: dump/LINE_3_sr22050/norm/dev/out_fastspeech2/
  num_workers: 5
  batch_size: 16
  group_size: 16
  accent_info: 0
train:
  out_dir: exp/LINE_3_sr22050_LINE_79_JSUT_NICT_LINE_wo_Teacher_finetuning_FS_GMM_num_gaussians_11/fastspeech2wGMM
  log_dir: tensorboard/LINE_3_sr22050_LINE_79_JSUT_NICT_LINE_wo_Teacher_finetuning_FS_GMM_num_gaussians_11_fastspeech2wGMM
  max_train_steps: -1
  nepochs: 500
  checkpoint_epoch_interval: 100
  eval_epoch_interval: 50
  vocoder_name: hifigan
  vocoder_config: conf/train_hifigan/model/hifigan.yaml
  vocoder_weight_path: exp/LINE_3_sr22050_LINE_6/hifigan/latest.pth
  sampling_rate: 22050
  mel_scaler_path: dump/LINE_3_sr22050/norm/out_fastspeech2_mel_scaler.joblib
  max_wav_value: 32768.0
  optim:
    optimizer:
      name: Adam
      params:
        lr: 0.0625
        betas:
        - 0.9
        - 0.98
        eps: 1.0e-09
        weight_decay: 0.0
    lr_scheduler:
      _target_: vc_tts_template.fastspeech2.optimizer.ScheduledOptim
      warm_up_step: 2000
      anneal_steps:
      - 150000
      - 200000
      - 250000
      anneal_rate: 0.3
      max_lr_scale: 0.016
  criterion:
    _target_: vc_tts_template.fastspeech2wGMM.loss.FastSpeech2Loss
    pitch_feature_level: 1
    energy_feature_level: 1
    beta: 0.02
    g_beta: 0.02
  pretrained:
    checkpoint: null
    optimizer_reset: true
